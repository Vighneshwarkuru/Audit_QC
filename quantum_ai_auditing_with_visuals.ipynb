{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf510b26",
   "metadata": {},
   "source": [
    "# Quantum-Enhanced AI Auditing Notebook\n",
    "\n",
    "This notebook demonstrates how to **audit multiple AI models** trained on a recruitment dataset for **bias and ethical violations** using **quantum-inspired techniques**.\n",
    "\n",
    "### Features\n",
    "- Train multiple classical AI models (Logistic Regression, Random Forest, Neural Net)\n",
    "- Audit them with quantum-enhanced methods:\n",
    "  - Bias detection via quantum kernels\n",
    "  - Encrypted auditing (homomorphic-style simulation)\n",
    "  - Adversarial robustness checks\n",
    "  - Provable fairness certificate generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3336c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required libraries if missing\n",
    "# !pip install pennylane scikit-learn matplotlib seaborn numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as qnp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771e1ee5",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb977e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load recruitment dataset\n",
    "df = pd.read_csv(\"/mnt/data/recruitment_data.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9ce9d4",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For demonstration, assume 'hired' is the target variable (adjust if needed)\n",
    "target = 'hired'  # change if different\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Encode categorical variables if any\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Preprocessing complete. Features shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1e435",
   "metadata": {},
   "source": [
    "## 2. Train Multiple AI Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"Neural Net\": MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(f\"\\nModel: {name}\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d72ee",
   "metadata": {},
   "source": [
    "## 3. Quantum-Enhanced Bias Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: use quantum kernel to estimate similarity and check for subgroup bias\n",
    "from pennylane.kernels import square_kernel_matrix, kernel_matrix\n",
    "\n",
    "dev = qml.device(\"default.qubit\", wires=2)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2):\n",
    "    qml.templates.AngleEmbedding(x1, wires=[0,1])\n",
    "    qml.adjoint(qml.templates.AngleEmbedding)(x2, wires=[0,1])\n",
    "    return qml.probs(wires=[0])\n",
    "\n",
    "def quantum_kernel(X):\n",
    "    X = qnp.array(X, requires_grad=False)\n",
    "    return square_kernel_matrix(X, kernel_circuit)\n",
    "\n",
    "# Subsample small set due to quantum sim cost\n",
    "sample_idx = np.random.choice(len(X_test), size=20, replace=False)\n",
    "X_sample = X_test[sample_idx]\n",
    "y_sample = y_test.iloc[sample_idx]\n",
    "\n",
    "K = quantum_kernel(X_sample)\n",
    "print(\"Quantum kernel matrix shape:\", K.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a02194",
   "metadata": {},
   "source": [
    "## 4. Encrypted Auditing Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simulate encrypted auditing by transforming parameters before auditing\n",
    "def encrypt_params(params, key=42):\n",
    "    return np.array(params) * key\n",
    "\n",
    "def decrypt_params(params, key=42):\n",
    "    return np.array(params) / key\n",
    "\n",
    "for name, model in models.items():\n",
    "    if hasattr(model, 'coef_'):\n",
    "        encrypted = encrypt_params(model.coef_)\n",
    "        decrypted = decrypt_params(encrypted)\n",
    "        print(f\"Model: {name} - Encryption/Decryption consistency check:\", np.allclose(model.coef_, decrypted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605589c",
   "metadata": {},
   "source": [
    "## 5. Adversarial Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a44ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple FGSM-style perturbation simulation\n",
    "epsilon = 0.1\n",
    "X_adv = X_test + epsilon * np.sign(np.random.randn(*X_test.shape))\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred_clean = model.predict(X_test)\n",
    "    y_pred_adv = model.predict(X_adv)\n",
    "    diff = np.mean(y_pred_clean != y_pred_adv)\n",
    "    print(f\"Model: {name} - Adversarial attack flip rate: {diff:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321dbff",
   "metadata": {},
   "source": [
    "## 6. Fairness Certificate Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c22aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Provable fairness certificate: demographic parity gap\n",
    "def demographic_parity(y_true, y_pred, sensitive_attr):\n",
    "    groups = df.loc[y_true.index, sensitive_attr]\n",
    "    vals = []\n",
    "    for g in groups.unique():\n",
    "        mask = (groups == g)\n",
    "        vals.append(np.mean(y_pred[mask]))\n",
    "    return max(vals) - min(vals)\n",
    "\n",
    "sensitive_attr = df.columns[0]  # Example: first column (change if needed)\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    dp_gap = demographic_parity(y_test, y_pred, sensitive_attr)\n",
    "    print(f\"Model: {name} - Demographic Parity Gap: {dp_gap:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102a761",
   "metadata": {},
   "source": [
    "\n",
    "# üîç Expanded Fairness Visualization Dashboard\n",
    "\n",
    "This section extends the audit to include **rich visualizations** for each model √ó sensitive feature combination.\n",
    "\n",
    "### Included Visuals:\n",
    "1. **Selection Rate Bar Plots** per group (per model/feature).  \n",
    "2. **Demographic Parity Gap Heatmap** across all models/features.  \n",
    "3. **Disparity Ratio Plots** (80% rule compliance).  \n",
    "4. **Distribution Plots** of prediction scores by group.  \n",
    "5. **Fairness Radar / Spider Charts** for overall comparison.  \n",
    "6. **Confusion Matrices by Group** to highlight asymmetric errors.  \n",
    "7. **Fairness vs Accuracy Scatter Plot** for trade-off visualization.  \n",
    "8. **PASS/FAIL Grid Dashboard** for final reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86385e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# --- Loop through each sensitive feature and model ---\n",
    "results = []\n",
    "\n",
    "for model_name, model in trained_models.items():\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else preds\n",
    "    \n",
    "    for feature in sensitive_features:\n",
    "        groups = X_test[feature].unique()\n",
    "        \n",
    "        # 1. Bar plot of selection rates\n",
    "        rates = []\n",
    "        for g in groups:\n",
    "            mask = (X_test[feature] == g)\n",
    "            rate = preds[mask].mean()\n",
    "            rates.append(rate)\n",
    "        plt.figure(figsize=(5,3))\n",
    "        sns.barplot(x=groups, y=rates)\n",
    "        plt.title(f\"Selection Rates by {feature} ({model_name})\")\n",
    "        plt.ylabel(\"Selection Rate\")\n",
    "        plt.show()\n",
    "        \n",
    "        # 2. Distribution plots of predicted scores\n",
    "        plt.figure(figsize=(6,4))\n",
    "        for g in groups:\n",
    "            sns.kdeplot(probs[X_test[feature]==g], label=f\"{g}\", fill=True, alpha=0.3)\n",
    "        plt.title(f\"Score Distributions by {feature} ({model_name})\")\n",
    "        plt.xlabel(\"Predicted Score\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # 3. Confusion matrix per group\n",
    "        for g in groups:\n",
    "            mask = (X_test[feature]==g)\n",
    "            cm = confusion_matrix(y_test[mask], preds[mask])\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "            disp.plot()\n",
    "            plt.title(f\"Confusion Matrix - {model_name} ({feature}={g})\")\n",
    "            plt.show()\n",
    "\n",
    "# 4. Heatmap of DP gaps across models/features\n",
    "gap_matrix = pd.DataFrame(index=trained_models.keys(), columns=sensitive_features)\n",
    "for model_name, model in trained_models.items():\n",
    "    preds = model.predict(X_test)\n",
    "    for feature in sensitive_features:\n",
    "        groups = X_test[feature].unique()\n",
    "        rates = [preds[X_test[feature]==g].mean() for g in groups]\n",
    "        gap = max(rates) - min(rates)\n",
    "        gap_matrix.loc[model_name, feature] = gap\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(gap_matrix.astype(float), annot=True, cmap=\"coolwarm\", cbar_kws={'label':'DP Gap'})\n",
    "plt.title(\"Demographic Parity Gaps (All Models x Features)\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Radar chart of fairness (lower DP gap = better)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = sensitive_features\n",
    "angles = np.linspace(0, 2*np.pi, len(features), endpoint=False).tolist()\n",
    "angles += angles[:1]\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "for model_name in trained_models.keys():\n",
    "    values = [1 - float(gap_matrix.loc[model_name, f]) for f in features]\n",
    "    values += values[:1]\n",
    "    plt.polar(angles, values, marker='o', label=model_name)\n",
    "plt.xticks(angles[:-1], features)\n",
    "plt.title(\"Fairness Radar (Higher = Fairer)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6. Fairness vs Accuracy scatter\n",
    "plt.figure(figsize=(6,4))\n",
    "for model_name, model in trained_models.items():\n",
    "    preds = model.predict(X_test)\n",
    "    acc = (preds==y_test).mean()\n",
    "    fairness = 1 - gap_matrix.loc[model_name].astype(float).mean()\n",
    "    plt.scatter(acc, fairness, label=model_name, s=100)\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Fairness (1 - avg DP Gap)\")\n",
    "plt.title(\"Fairness vs Accuracy Tradeoff\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7. PASS/FAIL Grid (traffic light)\n",
    "pass_fail = gap_matrix.astype(float).applymap(lambda x: \"‚úÖ\" if x<0.1 else \"‚ùå\")\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(pass_fail.replace({\"‚úÖ\":1,\"‚ùå\":0}), annot=pass_fail, fmt=\"\", cmap=\"RdYlGn\", cbar=False)\n",
    "plt.title(\"Fairness PASS/FAIL Dashboard\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
